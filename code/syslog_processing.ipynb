{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output CSV file paths\n",
    "input_csv_name = \"GPN_Syslog_10000.csv\"\n",
    "input_dir = \"data\"\n",
    "output_dir = \"processed_data\"\n",
    "if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "output_csv_name = input_csv_name[:-4] + \"_output\" + \".csv\"\n",
    "input_csv_path = os.path.join(input_dir,input_csv_name)\n",
    "output_csv_path = os.path.join(output_dir,output_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = r\"(?P<vendor>[A-Z]+)-(?P<physical_site_id>\\d+)_(?P<geolocation_code>[A-Z\\d]+)-(?P<router_type>[A-Z\\d]+)_(?P<router_model_number>[A-Z\\d]+)-(?P<router_importance>[A-Z\\d]+) (?P<vendor_identifier>%%)(?P<version_number>\\d+)(?P<module_name>[A-Z]+)/(?P<severity>\\d+)/(?P<log_type>[A-Z_]+)(?P<log_status>[\\(\\)a-z]+):CID=(?P<cid>[0-9a-zA-Z]+);(?P<description>.+)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_info(message):\n",
    "    # Extract timestamp\n",
    "    timestamp_str = message.split(' ')[0:4]\n",
    "    timestamp_str = ' '.join(timestamp_str)\n",
    "    dt = datetime.strptime(timestamp_str, \"%b %d %Y %H:%M:%S\")\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day_of_month = dt.day\n",
    "    hour = dt.hour\n",
    "    minute = dt.minute\n",
    "    second = dt.second\n",
    "    millisecond = dt.microsecond // 1000\n",
    "    day_of_week = dt.weekday()  # Monday = 0, Sunday = 6\n",
    "    day_of_year = dt.timetuple().tm_yday\n",
    "    week_of_year = dt.isocalendar()[1]\n",
    "    is_weekend = int(dt.weekday() >= 5)\n",
    "    seconds_since_midnight = hour * 3600 + minute * 60 + second\n",
    "    time_of_day_bucket = 'Morning' if hour < 12 else 'Afternoon' if hour < 18 else 'Evening' if hour < 21 else 'Night'\n",
    "    time_dict = {\n",
    "        'timestamp': timestamp_str,\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'day_of_month': day_of_month,\n",
    "        'hour': hour,\n",
    "        'minute': minute,\n",
    "        'second': second,\n",
    "        'millisecond': millisecond,\n",
    "        'day_of_week': day_of_week,\n",
    "        'day_of_year': day_of_year,\n",
    "        'week_of_year': week_of_year,\n",
    "        'is_weekend': is_weekend,\n",
    "        'seconds_since_midnight': seconds_since_midnight,\n",
    "        'time_of_day_bucket': time_of_day_bucket\n",
    "    }\n",
    "    return time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_time_info_from_message(message):\n",
    "    # Find the position of the first colon\n",
    "    first_colon_pos = message.find(':')\n",
    "\n",
    "    # Find the position of the second colon by starting the search after the first colon\n",
    "    second_colon_pos = message.find(':', first_colon_pos + 1)\n",
    "\n",
    "    # Slice the string two characters after the second colon\n",
    "    truncated_message = message[second_colon_pos + 4:]\n",
    "\n",
    "    # Print the truncated message\n",
    "    return truncated_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_description(description):\n",
    "    if description:\n",
    "        opening_bracket_pos = description.find('(')\n",
    "        if opening_bracket_pos >= 0:\n",
    "            \n",
    "            # Slice the string and separate metadata\n",
    "            metadata = description[opening_bracket_pos + 1:-1]\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(\"no metadata available inside the description\")\n",
    "            metadata = \"\" \n",
    "    else:\n",
    "        print(\"no description and hence no metadata\")\n",
    "        metadata = \"\"\n",
    "        \n",
    "    return metadata    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_network_info(pattern,message):\n",
    "    matching = re.search(pattern, message)\n",
    "    if matching:\n",
    "        extracted_info = matching.groupdict()\n",
    "        description = extracted_info.get(\"description\")\n",
    "        metadata = extract_metadata_from_description(description=description)\n",
    "        extracted_info[\"metadata\"] = metadata\n",
    "        return extracted_info\n",
    "    else:\n",
    "        # Return empty strings for all expected fields if pattern does not match\n",
    "        return {\n",
    "            \"vendor\": \"\",\n",
    "            \"physical_site_id\": \"\",\n",
    "            \"geolocation_code\": \"\",\n",
    "            \"router_type\": \"\",\n",
    "            \"router_model_number\": \"\",\n",
    "            \"router_importance\": \"\",\n",
    "            \"vendor_identifier\": \"\",\n",
    "            \"version_number\": \"\",\n",
    "            \"module_name\": \"\",\n",
    "            \"severity\": \"\",\n",
    "            \"log_type\": \"\",\n",
    "            \"log_status\": \"\",\n",
    "            \"cid\": \"\",\n",
    "            \"description\": \"\",\n",
    "            \"metadata\": \"\",\n",
    "        }   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headers for the new CSV file\n",
    "headers = [\n",
    "    'timestamp_of_received_log',\n",
    "    'timestamp_of_message',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day_of_month',\n",
    "    'hour',\n",
    "    'minute',\n",
    "    'second',\n",
    "    'millisecond',\n",
    "    'day_of_week',\n",
    "    'day_of_year',\n",
    "    'week_of_year',\n",
    "    'is_weekend',\n",
    "    'seconds_since_midnight',\n",
    "    'time_of_day_bucket',\n",
    "    'vendor', \n",
    "    'physical_site_id', \n",
    "    'geolocation_code', \n",
    "    'router_type', \n",
    "    'router_model_number',\n",
    "    'router_importance', \n",
    "    'vendor_identifier', \n",
    "    'version_number', \n",
    "    'module_name', \n",
    "    'severity',\n",
    "    'log_type', \n",
    "    'log_status', \n",
    "    'cid', \n",
    "    'description', \n",
    "    'metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\GPN_Syslog.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Open the input CSV file for reading and the output CSV file for writing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m infile, \\\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;28mopen\u001b[39m(output_csv_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Create CSV reader and writer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(infile)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mnext\u001b[39m(csv_reader) \u001b[38;5;66;03m# skipping the header row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prabhav.gupta\\OneDrive - In2IT Technologies Pvt Ltd\\Documents\\AIOps\\iSense\\code\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\GPN_Syslog.csv'"
     ]
    }
   ],
   "source": [
    "# Open the input CSV file for reading and the output CSV file for writing\n",
    "with open(input_csv_path, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_csv_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "    # Create CSV reader and writer\n",
    "    csv_reader = csv.reader(infile)\n",
    "    next(csv_reader) # skipping the header row\n",
    "    csv_writer = csv.DictWriter(outfile, fieldnames=headers)\n",
    "\n",
    "    # Write the header to the new CSV file\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    # Process each row in the input CSV\n",
    "    for row in csv_reader:\n",
    "        print(row)\n",
    "        if len(row) < 3:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        timestamp_of_received_log = row[0]\n",
    "        # Extract the message from the third column\n",
    "        message = row[2]\n",
    "\n",
    "        time_dict = extract_time_info(message=message)\n",
    "        final_time_dict = {\"timestamp_of_received_log\": timestamp_of_received_log} | time_dict\n",
    "        truncated_message = remove_time_info_from_message(message=message)\n",
    "        network_info_dict = extract_network_info(pattern=pattern1, message=truncated_message)\n",
    "        extracted_data = final_time_dict | network_info_dict\n",
    "\n",
    "        # Write the extracted data to the new CSV file\n",
    "        \n",
    "        data_to_write = {\n",
    "            'timestamp_of_received_log': extracted_data.get('timestamp_of_received_log', ''),\n",
    "            'timestamp_of_message': extracted_data.get('timestamp', ''),\n",
    "            'year': extracted_data.get('year', ''),\n",
    "            'month': extracted_data.get('month', ''),\n",
    "            'day_of_month': extracted_data.get('day_of_month', ''),\n",
    "            'hour': extracted_data.get('hour', ''),\n",
    "            'minute': extracted_data.get('minute', ''),\n",
    "            'second': extracted_data.get('second', ''),\n",
    "            'millisecond': extracted_data.get('millisecond', ''),\n",
    "            'day_of_week': extracted_data.get('day_of_week', ''),\n",
    "            'day_of_year': extracted_data.get('day_of_year', ''),\n",
    "            'week_of_year': extracted_data.get('week_of_year', ''),\n",
    "            'is_weekend': extracted_data.get('is_weekend', ''),\n",
    "            'seconds_since_midnight': extracted_data.get('seconds_since_midnight', ''),\n",
    "            'time_of_day_bucket': extracted_data.get('time_of_day_bucket', ''),\n",
    "            'vendor': extracted_data.get('vendor', ''),\n",
    "            'physical_site_id': extracted_data.get('physical_site_id', ''),\n",
    "            'geolocation_code': extracted_data.get('geolocation_code', ''),\n",
    "            'router_type': extracted_data.get('router_type', ''),\n",
    "            'router_model_number': extracted_data.get('router_model_number', ''),\n",
    "            'router_importance': extracted_data.get('router_importance', ''),\n",
    "            'vendor_identifier': extracted_data.get('vendor_identifier', ''),\n",
    "            'version_number': extracted_data.get('version_number', ''),\n",
    "            'module_name': extracted_data.get('module_name', ''),\n",
    "            'severity': extracted_data.get('severity', ''),\n",
    "            'log_type': extracted_data.get('log_type', ''),\n",
    "            'log_status': extracted_data.get('log_status', ''),\n",
    "            'cid': extracted_data.get('cid', ''),\n",
    "            'description': extracted_data.get('description', ''),\n",
    "            'metadata': extracted_data.get('metadata', '')\n",
    "        }\n",
    "        csv_writer.writerow(data_to_write)\n",
    "\n",
    "print(\"CSV processing complete. Data written to:\", output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def standardising_live_message(message):\n",
    "        message_dict = json.loads(message)\n",
    "        raw_msg = message_dict.get('payload','')\n",
    "        if raw_msg != '':\n",
    "            index = raw_msg.find('>')\n",
    "            msg_str = raw_msg[index+1:]\n",
    "            return msg_str\n",
    "        else:\n",
    "            return ''   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string_live_message = '{\"schema\":null,\"payload\":\"<188>Sep  3 2024 05:19:17 GPN-0484_GEO-MUK-HOS_AR12-01 %%01IFPDT/4/IF_STATE(l)[133047]:Interface GigabitEthernet0/0/2 has turned into UP state.\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_live_message = standardising_live_message(json_string_live_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep  3 2024 05:19:17 GPN-0484_GEO-MUK-HOS_AR12-01 %%01IFPDT/4/IF_STATE(l)[133047]:Interface GigabitEthernet0/0/2 has turned into UP state.\n"
     ]
    }
   ],
   "source": [
    "print(standard_live_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "['Sep', '', '3', '2024', '05:19:17', 'GPN-0484_GEO-MUK-HOS_AR12-01', '%%01IFPDT/4/IF_STATE(l)[133047]:Interface', 'GigabitEthernet0/0/2', 'has', 'turned', 'into', 'UP', 'state.']\n",
      "None\n",
      "['Sep', '3', '2024', '05:19:17']\n",
      "Sep 3 2024 05:19:17\n"
     ]
    }
   ],
   "source": [
    "time_dict = extract_time_info(message=standard_live_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ['Sep', '', '3', '2024', '05:19:17', 'GPN-0484_GEO-MUK-HOS_AR12-01', '%%01IFPDT/4/IF_STATE(l)[133047]:Interface', 'GigabitEthernet0/0/2', 'has', 'turned', 'into', 'UP', 'state.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sep', '3', '2024', '05:19:17', 'GPN-0484_GEO-MUK-HOS_AR12-01', '%%01IFPDT/4/IF_STATE(l)[133047]:Interface', 'GigabitEthernet0/0/2', 'has', 'turned', 'into', 'UP', 'state.']\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syslog_processing import Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'Automatic record:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.extract_unhappy_status_from_description('j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'hellog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'error' in 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "descrip = 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_time_info(message):\n",
    "    # Extract timestamp\n",
    "    split_message = message.split(' ')\n",
    "    if split_message[1] == '':\n",
    "        print('here')\n",
    "        print(split_message)\n",
    "        split_message_2 = split_message.remove('')\n",
    "        print(split_message_2)\n",
    "    timestamp_str = split_message[0:4]    \n",
    "    print(timestamp_str)\n",
    "    timestamp_str = ' '.join(timestamp_str)\n",
    "    print(timestamp_str)\n",
    "    try:\n",
    "        dt = datetime.strptime(timestamp_str, \"%b %d %Y %H:%M:%S\")\n",
    "    except Exception as e:\n",
    "        dt = datetime.strptime('Jan 01 0001 01:01:01', \"%b %d %Y %H:%M:%S\")  \n",
    "    print(dt)    \n",
    "    print(type(dt))    \n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day_of_month = dt.day\n",
    "    hour = dt.hour\n",
    "    minute = dt.minute\n",
    "    second = dt.second\n",
    "    millisecond = dt.microsecond // 1000\n",
    "    day_of_week = dt.weekday()  # Monday = 0, Sunday = 6\n",
    "    day_of_year = dt.timetuple().tm_yday\n",
    "    week_of_year = dt.isocalendar()[1]\n",
    "    is_weekend = int(dt.weekday() >= 5)\n",
    "    seconds_since_midnight = hour * 3600 + minute * 60 + second\n",
    "    time_of_day_bucket = 'Morning' if hour < 12 else 'Afternoon' if hour < 18 else 'Evening' if hour < 21 else 'Night'\n",
    "    time_dict = {\n",
    "        'timestamp': timestamp_str,\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'day_of_month': day_of_month,\n",
    "        'hour': hour,\n",
    "        'minute': minute,\n",
    "        'second': second,\n",
    "        'millisecond': millisecond,\n",
    "        'day_of_week': day_of_week,\n",
    "        'day_of_year': day_of_year,\n",
    "        'week_of_year': week_of_year,\n",
    "        'is_weekend': is_weekend,\n",
    "        'seconds_since_midnight': seconds_since_midnight,\n",
    "        'time_of_day_bucket': time_of_day_bucket\n",
    "    }\n",
    "    return time_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "message = '2024-9-24 10:02:17 GPN-0041_CHA-MAX-HOS_AR12-01 %%01INFO/4/SUPPRESS_LOG(l)[26051]:Last message repeated 3 times.(InfoID=3247640584, ModuleName=LLDP, InfoAlias=BAD_PACKET)'\n",
    "# message ='Sep 24 2024 10:02:08 GPN-1205_BOI-SEC-SCH_AR12-01 %%01QOS/4/SACL_LOG(l)[10240]:Ipv4 acl 3500,rule 30 permit 17 10.204.183.254(48618)-> 178.62.244.63(53) (1) packets.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-9-24', '10:02:17', 'GPN-0041_CHA-MAX-HOS_AR12-01', '%%01INFO/4/SUPPRESS_LOG(l)[26051]:Last']\n",
      "2024-9-24 10:02:17 GPN-0041_CHA-MAX-HOS_AR12-01 %%01INFO/4/SUPPRESS_LOG(l)[26051]:Last\n",
      "0001-01-01 01:01:01\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "d = extract_time_info(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2024-9-24 10:02:17 GPN-0041_CHA-MAX-HOS_AR12-01 %%01INFO/4/SUPPRESS_LOG(l)[26051]:Last',\n",
       " 'year': 1,\n",
       " 'month': 1,\n",
       " 'day_of_month': 1,\n",
       " 'hour': 1,\n",
       " 'minute': 1,\n",
       " 'second': 1,\n",
       " 'millisecond': 0,\n",
       " 'day_of_week': 0,\n",
       " 'day_of_year': 1,\n",
       " 'week_of_year': 1,\n",
       " 'is_weekend': 0,\n",
       " 'seconds_since_midnight': 3661,\n",
       " 'time_of_day_bucket': 'Morning'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
