# -*- coding: utf-8 -*-
"""distilBERT 2-anomaly detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uuIbeU9BlSdQlcjFM0NxlRzubZl_rMIW
"""

import os
from syslog_processing import Processing
obj = Processing()
input_csv_name = "GPN_Syslog_10000.csv"
input_csv_path = "GPN_Syslog_10000.csv"

"""STEP 1: Preprocess the Log Data for a particular router."""

desc = obj.get_specific_description(input_csv_path= input_csv_path,physical_site_id='0001', geolocation_code='TLK', device_role='CR', device_model_number='M14', device_importance='01')
print(desc)
len(desc)

pip install transformers scikit-learn torch

"""Step 2: Initialize DistilBERT Model and Tokenizer"""

import torch
from transformers import DistilBertTokenizer, DistilBertModel

# Initialize the DistilBERT model and tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertModel.from_pretrained('distilbert-base-uncased')

"""Step 3: Function to Generate Log Embeddings"""

def get_embeddings(logs):
    # Tokenize and encode each log message
    inputs = tokenizer(logs, return_tensors="pt", padding=True, truncation=True, max_length=128)

    # Get the embeddings from the last hidden layer of DistilBERT
    with torch.no_grad():
        outputs = model(**inputs)

    # Take the mean of the hidden states as the log's embedding
    embeddings = outputs.last_hidden_state.mean(dim=1)
    return embeddings.numpy()

"""Step 4: Generate Embeddings for All Logs"""

log_embeddings = get_embeddings(desc)

"""Step 5: Normalize the Embeddings (Optional but Recommended)"""

from sklearn.preprocessing import StandardScaler

# Normalize the embeddings
scaler = StandardScaler()
log_embeddings_scaled = scaler.fit_transform(log_embeddings)

"""Step 6: Apply Isolation Forest for Anomaly Detection"""

from sklearn.ensemble import IsolationForest

# Fit Isolation Forest model
iso_forest = IsolationForest(contamination=0.05, random_state=42)
iso_forest.fit(log_embeddings_scaled)

"""Step 7: Predict Anomalies"""

# Predict anomalies
anomaly_labels = iso_forest.predict(log_embeddings_scaled)

# Print logs flagged as anomalies
for i, log in enumerate(desc):
    if anomaly_labels[i] == -1:
        print(f"Anomaly Detected: {log}")

"""In the log messages, there are many failures that are recurring (like snmp login fails, ip lock/unlock authentication fails). The anomalies detected above are the failures which occur rarely in the logs, posibly hinting at being more important to look at."""

